{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "### Fetch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I:349 Error:0.10881979854066498 Correct:1.099"
     ]
    }
   ],
   "source": [
    "images, labels = (x_train[:1000].reshape(1000, 28*28)/255, y_train[0:1000])\n",
    "one_hot_labels = np.zeros((len(labels), 10))\n",
    "for i,l in enumerate(labels):\n",
    "    one_hot_labels[i][l] = 1\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = x_test.reshape(len(x_test), 28*28)/255\n",
    "test_labels = np.zeros((len(y_test), 10))\n",
    "for i,l in enumerate(y_test):\n",
    "    test_labels[i][l] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "relu = lambda x: (x>=0)*x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size))-0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels))-0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        error += np.sum((labels[i:i+1]-layer_2)**2)\n",
    "        correct_cnt += int(np.argmax(layer_2)==np.argmax(labels[i:i+1]))\n",
    "        layer_2_delta = (labels[i:i+1]-layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "        weights_1_2 += alpha*layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha*layer_0.T.dot(layer_1_delta)\n",
    "    sys.stdout.write(\"\\r\" + \" I:\" + str(j) + \n",
    "                    \" Error:\" + str((error/len(images))) +\n",
    "                    \" Correct:\" + str(correct_cnt/len(images)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test-Err:[0.65340554 0.65340554] Test-Acc:[0.7073 0.7073]\n"
     ]
    }
   ],
   "source": [
    "if(j%10==0 or j==iterations-1):\n",
    "    error = correct_cnt = (0.0, 0)\n",
    "    for i in range(len(test_images)):\n",
    "        layer_0 = test_images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        error += np.sum((test_labels[i:i+1]-layer_2)**2)\n",
    "        correct_cnt += (np.argmax(layer_2)==np.argmax(test_labels[i:i+1]))\n",
    "    sys.stdout.write(\" Test-Err:\" + str(error/len(test_images)) + \n",
    "                     \" Test-Acc:\" + str(correct_cnt/len(test_images)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Train-Err:0.08854150378548294 Train-Acc:0.0289 Test-Err:[0.71811291 0.71811291] Test-Acc:[0.5418 0.5418]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.056442490520860096 Train-Acc:0.0647 Test-Err:[0.50199879 0.50199879] Test-Acc:[0.7365 0.7365]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.05305078554418434 Train-Acc:0.0681 Test-Err:[0.47819835 0.47819835] Test-Acc:[0.7621 0.7621]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.05081959946032416 Train-Acc:0.071 Test-Err:[0.45770377 0.45770377] Test-Acc:[0.7915 0.7915]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.049224387915888596 Train-Acc:0.0719 Test-Err:[0.44559247 0.44559247] Test-Acc:[0.7998 0.7998]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04626158977664231 Train-Acc:0.0742 Test-Err:[0.43086597 0.43086597] Test-Acc:[0.8145 0.8145]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04721649431897942 Train-Acc:0.0746 Test-Err:[0.44656634 0.44656634] Test-Acc:[0.7974 0.7974]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04630812403222845 Train-Acc:0.0744 Test-Err:[0.44504726 0.44504726] Test-Acc:[0.7901 0.7901]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04617832439825736 Train-Acc:0.0764 Test-Err:[0.42626659 0.42626659] Test-Acc:[0.8105 0.8105]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04622208611156365 Train-Acc:0.0749 Test-Err:[0.43532871 0.43532871] Test-Acc:[0.7871 0.7871]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04527249546256898 Train-Acc:0.0769 Test-Err:[0.4330339 0.4330339] Test-Acc:[0.8039 0.8039]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04397614513499588 Train-Acc:0.0778 Test-Err:[0.43555584 0.43555584] Test-Acc:[0.8099 0.8099]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.045111180330737397 Train-Acc:0.0778 Test-Err:[0.44236871 0.44236871] Test-Acc:[0.7871 0.7871]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04529434694429023 Train-Acc:0.0783 Test-Err:[0.43937599 0.43937599] Test-Acc:[0.811 0.811]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.044575177645079844 Train-Acc:0.0779 Test-Err:[0.44362682 0.44362682] Test-Acc:[0.8049 0.8049]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.045770795527593125 Train-Acc:0.0783 Test-Err:[0.44695851 0.44695851] Test-Acc:[0.7918 0.7918]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04564763173223734 Train-Acc:0.0774 Test-Err:[0.4377412 0.4377412] Test-Acc:[0.81 0.81]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.043981693637471495 Train-Acc:0.0801 Test-Err:[0.43039059 0.43039059] Test-Acc:[0.7963 0.7963]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.045300443069391384 Train-Acc:0.0782 Test-Err:[0.43269894 0.43269894] Test-Acc:[0.7955 0.7955]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.043346019294201336 Train-Acc:0.0784 Test-Err:[0.43672179 0.43672179] Test-Acc:[0.7997 0.7997]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.0442789534073302 Train-Acc:0.0796 Test-Err:[0.43652515 0.43652515] Test-Acc:[0.803 0.803]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.044126717222760105 Train-Acc:0.079 Test-Err:[0.43446379 0.43446379] Test-Acc:[0.8031 0.8031]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04342885005592593 Train-Acc:0.0777 Test-Err:[0.4261897 0.4261897] Test-Acc:[0.8102 0.8102]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.043167712663199326 Train-Acc:0.0803 Test-Err:[0.4290762 0.4290762] Test-Acc:[0.8058 0.8058]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.043056292066444186 Train-Acc:0.0788 Test-Err:[0.43647781 0.43647781] Test-Acc:[0.8055 0.8055]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.043334134228121414 Train-Acc:0.0789 Test-Err:[0.42126428 0.42126428] Test-Acc:[0.8053 0.8053]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04227573263494934 Train-Acc:0.079 Test-Err:[0.42288186 0.42288186] Test-Acc:[0.8102 0.8102]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04305538028123168 Train-Acc:0.0803 Test-Err:[0.43868362 0.43868362] Test-Acc:[0.8062 0.8062]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04250784948264756 Train-Acc:0.079 Test-Err:[0.43187552 0.43187552] Test-Acc:[0.7991 0.7991]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04287182094622112 Train-Acc:0.0792 Test-Err:[0.4334287 0.4334287] Test-Acc:[0.8028 0.8028]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04077557931736408 Train-Acc:0.0804 Test-Err:[0.43435963 0.43435963] Test-Acc:[0.7949 0.7949]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04157893956070977 Train-Acc:0.0793 Test-Err:[0.42807193 0.42807193] Test-Acc:[0.8036 0.8036]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04157381867229323 Train-Acc:0.0812 Test-Err:[0.43689113 0.43689113] Test-Acc:[0.8008 0.8008]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04188775720325881 Train-Acc:0.0817 Test-Err:[0.41948138 0.41948138] Test-Acc:[0.8134 0.8134]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.04080764414503774 Train-Acc:0.0814 Test-Err:[0.43159365 0.43159365] Test-Acc:[0.8012 0.8012]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Train-Err:0.0418831146757072 Train-Acc:0.0802 Test-Err:[0.42123031 0.42123031] Test-Acc:[0.8078 0.8078]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "relu = lambda x: (x>=0)*x\n",
    "relu2deriv = lambda x: x>=0\n",
    "alpha, iterations, hidden_size, pixels_per_image, num_labels = (0.005, 350, 40, 784, 10)\n",
    "weights_0_1 = 0.2*np.random.random((pixels_per_image, hidden_size))-0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size, num_labels))-0.1\n",
    "\n",
    "for j in range(iterations):\n",
    "    error, correct_cnt = (0.0, 0)\n",
    "    for i in range(len(images)):\n",
    "        layer_0 = images[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask*2\n",
    "        layer_2 = np.dot(layer_1, weights_1_2)\n",
    "        error += np.sum((labels[i:i+1]-layer_2)**2)\n",
    "        correct_cnt += int(np.argmax(layer_2)==np.argmax(labels[i:i+1]))\n",
    "        layer_2_delta = (labels[i:i+1]-layer_2)\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T)*relu2deriv(layer_1)\n",
    "        layer_1_delta *= dropout_mask\n",
    "        weights_1_2 += alpha*layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 += alpha*layer_0.T.dot(layer_1_delta)\n",
    "    if(j%10==0 or j==iterations-1):\n",
    "        test_error = test_correct_cnt = (0.0, 0)\n",
    "        for i in range(len(test_images)):\n",
    "            layer_0 = test_images[i:i+1]\n",
    "            layer_1 = relu(np.dot(layer_0, weights_0_1))\n",
    "            layer_2 = np.dot(layer_1, weights_1_2)\n",
    "            test_error += np.sum((test_labels[i:i+1]-layer_2)**2)\n",
    "            test_correct_cnt += (np.argmax(layer_2)==np.argmax(test_labels[i:i+1]))\n",
    "        sys.stdout.write(\" Train-Err:\" + str(error/len(test_images)) + \n",
    "                         \" Train-Acc:\" + str(correct_cnt/len(test_images)) +\n",
    "                        \" Test-Err:\" + str(test_error/len(test_images)) + \n",
    "                        \" Test-Acc:\" + str(test_correct_cnt/len(test_images)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
